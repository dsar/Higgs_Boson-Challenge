{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCML Project-1 ~ Team #60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from test import *\n",
    "\n",
    "from costs import compute_loss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (200,)\n",
      "original tX shape:  (200, 30)\n",
      "ids shape:  (200,)\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = \"../Data/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "#print the shape of the offset x matrix.\n",
    "print('y shape: ',y.shape)\n",
    "print('original tX shape: ',tX.shape)\n",
    "print('ids shape: ',ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Outliers - Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:  0  ->  35.0\n",
      "feature:  1  ->  0.0\n",
      "feature:  2  ->  0.0\n",
      "feature:  3  ->  0.0\n",
      "feature:  4  ->  144.0\n",
      "feature:  5  ->  144.0\n",
      "feature:  6  ->  144.0\n",
      "feature:  7  ->  0.0\n",
      "feature:  8  ->  0.0\n",
      "feature:  9  ->  0.0\n",
      "feature:  10  ->  0.0\n",
      "feature:  11  ->  0.0\n",
      "feature:  12  ->  144.0\n",
      "feature:  13  ->  0.0\n",
      "feature:  14  ->  0.0\n",
      "feature:  15  ->  0.0\n",
      "feature:  16  ->  0.0\n",
      "feature:  17  ->  0.0\n",
      "feature:  18  ->  0.0\n",
      "feature:  19  ->  0.0\n",
      "feature:  20  ->  0.0\n",
      "feature:  21  ->  0.0\n",
      "feature:  22  ->  0.0\n",
      "feature:  23  ->  87.0\n",
      "feature:  24  ->  87.0\n",
      "feature:  25  ->  87.0\n",
      "feature:  26  ->  144.0\n",
      "feature:  27  ->  144.0\n",
      "feature:  28  ->  144.0\n",
      "feature:  29  ->  0.0\n"
     ]
    }
   ],
   "source": [
    "outliers = count_outliers(tX,-999)\n",
    "for feature in range(tX.shape[1]):\n",
    "    print('feature: ',feature,' -> ',outliers[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 30\n",
      "(200, 31)\n",
      "standardized tX shape:  (200, 30)\n"
     ]
    }
   ],
   "source": [
    "#standardization\n",
    "# tX, mean_x, std_x = standardize(tX, mean_x=None, std_x=None)\n",
    "tX_train, _, _ = standardize_outliers(tX)\n",
    "print('standardized tX shape: ',tX.shape)\n",
    "# print('tX mean shape: ',mean_x.shape)\n",
    "# print('tX std shape: ',std_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram of output y\n",
    "plt.hist(y, bins=10, align='mid')\n",
    "plt.title(\"Histogram of output y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of y as a function of all its features (one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyse y as a function of all the other features (one by one)\n",
    "plot_features_by_y(y,tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gradient_descent import least_squares_GD\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX.shape[1])\n",
    "# Start gradient descent.\n",
    "gradient_losses, gradient_ws = least_squares_GD(y, tX, w_initial, gamma, max_iters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stochastic_gradient_descent import least_squares_SGD\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "batch_size = 1\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX.shape[1])\n",
    "# Start SGD.\n",
    "stoch_gradient_losses, stoch_gradient_ws = least_squares_SGD(y, tX, w_initial, batch_size, gamma, max_iters)\n",
    "\n",
    "min_stoch_i, min_stoch_loss = get_min_param_index(stoch_gradient_losses)\n",
    "print('min index: ',min_stoch_i)\n",
    "print('min loss: ',min_stoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.287011356531\n",
      "parameters w:  [  1.32072859e-01  -1.74548408e-01  -5.00980898e-01   2.73175014e-02\n",
      "   2.13390230e-01   3.93925310e-01   5.96666011e-01   3.15606760e-01\n",
      "  -7.58736928e-02  -8.60909375e+03  -3.52491021e-01   3.83822009e-02\n",
      "   1.24366889e-01   1.83641462e+03  -8.37425941e-02   3.75708779e-02\n",
      "   1.83863517e+03  -3.53866613e-02  -6.51340816e-02  -4.07964933e-02\n",
      "  -1.73901256e-01  -9.19789291e-02  -4.11455894e-01  -3.30316314e-02\n",
      "   6.68277778e-02  -8.70551927e-02  -1.54283157e-01  -7.00019248e-02\n",
      "  -6.61615669e-02   7.38826725e+03]\n"
     ]
    }
   ],
   "source": [
    "from least_squares import least_squares\n",
    "\n",
    "ls_wopt, ls_loss = least_squares(y,tX)\n",
    "print('loss=',ls_loss)\n",
    "print('parameters w: ',ls_wopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.     0.8  ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 1.     0.75 ]\n",
      " [ 5.     0.8  ]\n",
      " [ 0.     0.825]\n",
      " [ 5.     0.825]\n",
      " [ 2.     0.775]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.8  ]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.8  ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]]\n",
      "(200, 40)\n",
      "[[ 5.     0.8  ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 1.     0.75 ]\n",
      " [ 5.     0.8  ]\n",
      " [ 0.     0.825]\n",
      " [ 5.     0.825]\n",
      " [ 2.     0.775]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.8  ]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.8  ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]]\n",
      "(200, 40)\n",
      "[[ 5.     0.8  ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 1.     0.75 ]\n",
      " [ 5.     0.8  ]\n",
      " [ 0.     0.825]\n",
      " [ 5.     0.825]\n",
      " [ 2.     0.775]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.8  ]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.8  ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]]\n",
      "(200, 40)\n",
      "[[ 5.     0.8  ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 1.     0.75 ]\n",
      " [ 5.     0.8  ]\n",
      " [ 0.     0.825]\n",
      " [ 5.     0.825]\n",
      " [ 2.     0.775]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.8  ]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.8  ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]]\n",
      "(200, 40)\n",
      "[[ 5.     0.8  ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 1.     0.75 ]\n",
      " [ 5.     0.8  ]\n",
      " [ 0.     0.825]\n",
      " [ 5.     0.825]\n",
      " [ 2.     0.775]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.8  ]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.8  ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]]\n",
      "(200, 40)\n",
      "0.877118032703\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEdCAYAAAD5KpvoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18bd713f048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ridge_regression import cross_validation_ridge_regression\n",
    "from build_polynomial import build_poly\n",
    "from poly import *\n",
    "from build_polynomial import *\n",
    "\n",
    "min_rr_rmse,best_rr_lambda = (cross_validation_ridge_regression(y,tX,k_fold=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.     0.825]\n",
      " [ 5.     0.8  ]\n",
      " [ 2.     0.775]\n",
      " [ 5.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 4.     0.8  ]\n",
      " [ 0.     0.825]\n",
      " [ 5.     0.825]\n",
      " [ 1.     0.75 ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 3.     0.8  ]\n",
      " [ 4.     0.8  ]\n",
      " [ 4.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 5.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 1.     0.75 ]]\n",
      "(200, 52)\n",
      "loss:  0.284033488627\n",
      "parameters w:  [-0.0263187   0.01158362 -0.03933718 -0.04891752 -0.01838251 -0.0511348\n",
      " -0.01086517  0.00664632  0.00693832 -0.03589002  0.0146597   0.0027643\n",
      "  0.01849414  0.01061297 -0.0043979   0.00883833  0.0152619   0.00113195\n",
      "  0.0174042  -0.01392594  0.0146732  -0.00250006 -0.00819308 -0.01044038\n",
      " -0.01719831  0.00492555  0.03537614 -0.02481036 -0.00364749 -0.01590135\n",
      "  0.00790204  0.00335939  0.01418658  0.031905   -0.00810612  0.02822154\n",
      " -0.00466199 -0.00741689 -0.01253939 -0.01842252 -0.02202067  0.00434623\n",
      "  0.00228775 -0.01810308 -0.01709596 -0.01162247 -0.03530801 -0.00351131\n",
      " -0.02062029 -0.02021249 -0.04719723  0.032214  ]\n"
     ]
    }
   ],
   "source": [
    "from ridge_regression import ridge_regression\n",
    "\n",
    "best_deg = find_best_poly(y, tX_train[:,1:],test_RR)\n",
    "opt_tr = build_optimal(tX_train[:,1:], best_deg)\n",
    "w_ridge, ridge_loss = ridge_regression(y, opt_tr,best_rr_lambda)\n",
    "\n",
    "print('loss: ',ridge_loss)\n",
    "print('parameters w: ',w_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using gradient descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.     0.8  ]\n",
      " [ 2.     0.775]\n",
      " [ 2.     0.8  ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 5.     0.8  ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 3.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 2.     0.775]\n",
      " [ 0.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 2.     0.775]\n",
      " [ 5.     0.775]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]\n",
      " [ 0.     0.75 ]]\n",
      "(200, 26)\n",
      "Current iteration=0, the loss=0.6931471805599452\n",
      "Current iteration=1000, the loss=0.6894805130138838\n",
      "Current iteration=2000, the loss=0.6859511132297417\n",
      "Current iteration=3000, the loss=0.6824901078799939\n"
     ]
    }
   ],
   "source": [
    "from logistic_regression import logistic_regression_gradient_descent\n",
    "from plots import visualization\n",
    "\n",
    "best_deg = find_best_poly(y, tX_train[:,1:],test_LR)\n",
    "opt_tr = build_optimal(tX_train[:,1:], best_deg)\n",
    "lr_loss, lr_w = logistic_regression_gradient_descent(y, opt_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression using gradient descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle score Aproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD test\n",
      "parameters w:  [-0.03574765 -0.29307716 -0.25622237  0.02914541  0.01437547  0.15190617\n",
      "  0.22636287  0.28250279 -0.09065928  0.14286233 -0.14485509  0.04698598\n",
      "  0.18770091  0.1328155  -0.10799591  0.04080291  0.04158353 -0.05181993\n",
      " -0.10623274  0.09005564 -0.14231326 -0.00480513 -0.06340605  0.09870042\n",
      "  0.09999228 -0.16019252  0.08644647 -0.17649949 -0.11447075  0.12312552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_GD(y, tX, ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD test\n",
      "parameters w:  [-0.05156778 -0.18065851 -0.09073065 -0.00239607  0.02824679  0.05645477\n",
      "  0.01136668  0.14440678 -0.10286569  0.02112294 -0.1271831   0.07590447\n",
      "  0.08419775  0.05606966 -0.04511965  0.08109771 -0.13074    -0.03614835\n",
      " -0.08166958 -0.03843294 -0.11223096 -0.02342437 -0.01267796  0.05771319\n",
      "  0.08870854 -0.07798771  0.04068466 -0.08403514 -0.05952428  0.04321297]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_SGD(y, tX, ratio=0.2,max_iters=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LS(y, tX, ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_RR(y, opt_tr, ratio=0.2,lambda_=best_rr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_LR(y, tX, ratio=0.2,threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_RLR(y, tX, ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "weights = gradient_ws[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "weights = stoch_gradient_ws[min_stoch_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least Squares\n",
    "weights = ls_wopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "weights = w_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "weights = lr_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../Data/test.csv\" # TODO: download test data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test, _, _ = standardize_outliers(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../Data/results.csv' # TODO: fill in desired name of output file for submission\n",
    "# y_pred = predict_logistic_labels(weights, tX_test,threshold=0.5)\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from poly import build_optimal\n",
    "\n",
    "OUTPUT_PATH = '../Data/results.csv' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "tx = tX_test[:,1:]\n",
    "opt_tr = build_optimal(tx, best_deg)\n",
    "\n",
    "y_pred = predict_labels(w, opt_tr)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
