{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCML Project-1 ~ Team #60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data with dimensions  (250000, 30)\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = \"../Data/train.csv\"\n",
    "y_train, tx_train, _ = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "print(\"Loaded training data with dimensions \", tx_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful information on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count outliers - Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import count_outliers\n",
    "outliers = count_outliers(tx_train, -999)\n",
    "for feature in range(tx_train.shape[1]):\n",
    "    print('feature: ',feature,' -> ',outliers[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=2, align='mid')\n",
    "plt.title(\"Histogram of output y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of y as a function of all its features (one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import plot_features_by_y\n",
    "plot_features_by_y(y_train,tx_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank deficiency of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_rank = np.linalg.matrix_rank(tx_train)\n",
    "print('original tx_train rank: ',original_rank)\n",
    "# indices = np.arange(tx_train.shape[1])\n",
    "# for col in range(30):\n",
    "#     indices = np.delete(indices,col)\n",
    "#     rank = np.linalg.matrix_rank(tx_train[:,indices])\n",
    "#     indices = np.insert(indices,col,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import standardize_outliers\n",
    "# Standardize the data and replace undefined values with the mean, column by column\n",
    "tx_train, _, _ = standardize_outliers(tx_train, -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 8 8 8 8 7 8 7 5 4 6 0 8 6 8 0 7 8 5 8 2 7 3 7 8 0 6 8 7 8]\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import best_feature_degrees\n",
    "from cross_validation import test_LS\n",
    "\n",
    "best_degrees = best_feature_degrees(y_train, tx_train, test_LS, max_degree=8)\n",
    "print(best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created expanded data with shape  (250000, 184)\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import build_poly_by_feature\n",
    "tx_train = build_poly_by_feature(tx_train, best_degrees)\n",
    "\n",
    "print(\"Created expanded data with shape \", tx_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = {}\n",
    "s = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/work/Documents/PCML/Project/scripts/costs.py:6: RuntimeWarning: overflow encountered in square\n",
      "  return 1/2*np.mean(e**2)\n",
      "/Users/work/Documents/PCML/Project/scripts/helpers.py:106: RuntimeWarning: invalid value encountered in less_equal\n",
      "  y_pred[np.where(y_pred <= threshold)] = -1\n",
      "/Users/work/Documents/PCML/Project/scripts/helpers.py:107: RuntimeWarning: invalid value encountered in greater\n",
      "  y_pred[np.where(y_pred > threshold)] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated leaderboard score:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_gamma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e06e4974acbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Estimated leaderboard score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gd\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleast_squares_GD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_gamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gd\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_gamma' is not defined"
     ]
    }
   ],
   "source": [
    "from cross_validation import test_GD\n",
    "from implementations import least_squares_GD\n",
    "\n",
    "gammas = [0.01] #np.logspace(-3, 0, num=4) # TODO play with\n",
    "best_loss = 10000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    loss, score = test_GD(y_train, tx_train, gamma)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_gamma = gamma\n",
    "        best_score = score\n",
    "    # if score > best_score:\n",
    "    #     best_score = score\n",
    "    #     best_gamma = gamma\n",
    "    #     best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w[\"gd\"], _ = least_squares_GD(y_train, tx_train, np.zeros(tx_train.shape[1]), 50, best_gamma)\n",
    "s[\"gd\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_SGD\n",
    "from implementations import least_squares_SGD\n",
    "\n",
    "gammas = np.logspace(-3, 0, num=4) # TODO play with\n",
    "best_loss = 10000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    loss, score = test_SGD(y_train, tx_train, gamma)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_gamma = gamma\n",
    "        best_score = score\n",
    "    # if score > best_score:\n",
    "    #     best_score = score\n",
    "    #     best_gamma = gamma\n",
    "    #     best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w[\"sgd\"], _ = least_squares_SGD(y_train, tx_train, np.zeros(tx_train.shape[1]), 50, best_gamma)\n",
    "s[\"sgd\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated leaderboard score:  0.8103\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import test_LS\n",
    "from implementations import least_squares\n",
    "\n",
    "_, score = test_LS(y_train, tx_train)\n",
    "\n",
    "print(\"Estimated leaderboard score: \", score)\n",
    "w[\"ls\"], _ = least_squares(y_train, tx_train)\n",
    "s[\"ls\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_RR\n",
    "from implementations import ridge_regression\n",
    "\n",
    "lambdas = np.logspace(-15, 3, num=20)\n",
    "best_loss = 10000 # TODO change\n",
    "best_score = 0\n",
    "for lambda_ in lambdas:\n",
    "    loss, score = test_RR(y_train, tx_train, lambda_)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_lambda = lambda_\n",
    "        best_score = score\n",
    "    # if score > best_score:\n",
    "    #     best_score = score\n",
    "    #     best_lambda = lambda_\n",
    "    #     best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w, _ = ridge_regression(y_train, tx_train, best_lambda)\n",
    "s[\"rr\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_LR\n",
    "from implementations import logistic_regression\n",
    "\n",
    "gammas = np.logspace(-10, 3, 13)\n",
    "best_loss = 10000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    loss, score = test_LR(y_train, tx_train, gamma)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_gamma = gamma\n",
    "        best_score = score\n",
    "    # if score > best_score:\n",
    "    #     best_score = score\n",
    "    #     best_gamma = gamma\n",
    "    #     best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w[\"lr\"], _ = logistic_regression(y_train, tx_train, np.zeros(tx_train.shape[1]), 50, best_gamma)\n",
    "s[\"lr\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_RLR\n",
    "from implementations import reg_logistic_regression\n",
    "\n",
    "gammas = np.logspace(-2, 2, 3)\n",
    "lambdas = np.logspace(-2, 2, 3)\n",
    "best_loss = 10000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    for lambda_ in lambdas:\n",
    "        loss, score = test_RLR(y_train, tx_train, lambda_, gamma)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_gamma = gamma\n",
    "            best_lambda = lambda_\n",
    "            best_score = score\n",
    "        # if score > best_score:\n",
    "        #     best_score = score\n",
    "        #     best_gamma = gamma\n",
    "        #     best_lambda = lambda_\n",
    "        #     best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w[\"rlr\"], _ = reg_logistic_regression(y_train, tx_train, best_lambda, np.zeros(tx_train.shape[1]), 50, best_gamma)\n",
    "s[\"rlr\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls\n",
      "0.8103\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "for method, score in s.items():\n",
    "    if score > best:\n",
    "        best = score\n",
    "        best_method = method\n",
    "\n",
    "print(best_method)\n",
    "print(s[best_method])\n",
    "weights = w[best_method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import standardize_outliers\n",
    "from feature_selection import build_poly_by_feature\n",
    "\n",
    "DATA_TEST_PATH = \"../Data/test.csv\"\n",
    "_, tx_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tx_test, _, _ = standardize_outliers(tx_test, -999)\n",
    "tx_test = build_poly_by_feature(tx_test, best_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if best_method in [ \"lr\", \"rlr\" ]:\n",
    "    y_pred = predict_logistic_labels(weights, tx_test, threshold = 0.5)\n",
    "else:\n",
    "    y_pred = predict_labels(weights, tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"../Data/results.csv\"\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
