{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCML Project-1 ~ Team #60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data with dimensions  (250000, 30)\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_PATH = \"../Data/train.csv\"\n",
    "y_train, tx_train, _ = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "print(\"Loaded training data with dimensions \", tx_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful information on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count outliers - Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import count_outliers\n",
    "outliers = count_outliers(tx_train, -999)\n",
    "for feature in range(tx_train.shape[1]):\n",
    "    print('feature: ',feature,' -> ',outliers[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=2, align='mid')\n",
    "plt.title(\"Histogram of output y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of y as a function of all its features (one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import plot_features_by_y\n",
    "plot_features_by_y(y_train,tx_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Deficiency of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original_rank = np.linalg.matrix_rank(tx_train)\n",
    "print('original tx_train rank: ',original_rank)\n",
    "# indices = np.arange(tx_train.shape[1])\n",
    "# for col in range(30):\n",
    "#     indices = np.delete(indices,col)\n",
    "#     rank = np.linalg.matrix_rank(tx_train[:,indices])\n",
    "#     indices = np.insert(indices,col,col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our matrix-rank is 30 which means that we do not have any ill-conditioning between our columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx standardized shape:  (250000, 30)\n"
     ]
    }
   ],
   "source": [
    "from data_preparation import standardize_outliers\n",
    "# Standardize the data and replace undefined values with the mean, column by column\n",
    "tx_train, _, _ = standardize_outliers(tx_train, -999)\n",
    "print('tx standardized shape: ',tx_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection and polynomial expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from quadratic_array import *\n",
    "indices = select_features(tx_train, y_train, 0.05)\n",
    "tx_train = tx_train[:,indices]\n",
    "indices, len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tx_train = np.c_[np.ones(tx_train.shape[0]), tx_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 12 12  9  7 12 12 12  6 12 12  0  9 12  9  3 12 11  4  8  7 11  3  7  9\n",
      "  0 10 10 12 12]\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import best_feature_degrees\n",
    "from implementations import least_squares\n",
    "\n",
    "best_degrees = best_feature_degrees(y_train, tx_train, least_squares, max_degree=12)\n",
    "print(best_degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created expanded data with shape  (250000, 268)\n"
     ]
    }
   ],
   "source": [
    "from feature_selection import build_poly_by_feature\n",
    "tx_train = build_poly_by_feature(tx_train, best_degrees)\n",
    "\n",
    "print(\"Created expanded data with shape \", tx_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = {}\n",
    "s = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_GD\n",
    "from implementations import least_squares_GD\n",
    "\n",
    "gammas = np.logspace(-1, 0, num=5)\n",
    "best_loss = 1000000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    loss, score = test_GD(y_train, tx_train, gamma)\n",
    "    #if loss < best_loss:\n",
    "    #    best_loss = loss\n",
    "    #    best_gamma = gamma\n",
    "    #    best_score = score\n",
    "    print(gamma, score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_gamma = gamma\n",
    "        best_loss = loss\n",
    "\n",
    "print('best gamma: ', best_gamma)\n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w[\"gd\"], _ = least_squares_GD(y_train, tx_train, np.zeros(tx_train.shape[1]), 1000, best_gamma)\n",
    "s[\"gd\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_SGD\n",
    "from implementations import least_squares_SGD\n",
    "\n",
    "gammas = np.logspace(-2, -0.05, num=5)\n",
    "best_loss = 1000000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    loss, score = test_SGD(y_train, tx_train, gamma)\n",
    "    #if loss < best_loss:\n",
    "    #    best_loss = loss\n",
    "    #    best_gamma = gamma\n",
    "    #    best_score = score\n",
    "    print(gamma, score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_gamma = gamma\n",
    "        best_loss = loss\n",
    "\n",
    "print('best gamma: ', best_gamma)\n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "w[\"sgd\"], _ = least_squares_SGD(y_train, tx_train, np.zeros(tx_train.shape[1]), 10000, best_gamma)\n",
    "s[\"sgd\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated leaderboard score:  0.817816\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import test_LS\n",
    "from implementations import least_squares\n",
    "\n",
    "_, score = test_LS(y_train, tx_train)\n",
    "\n",
    "print(\"Estimated leaderboard score: \", score)\n",
    "w[\"ls\"], _ = least_squares(y_train, tx_train)\n",
    "s[\"ls\"] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-15 0.8178\n",
      "1e-14 0.817828\n",
      "1e-13 0.817808\n",
      "1e-12 0.817848\n",
      "1e-11 0.817904\n",
      "1e-10 0.817888\n",
      "1e-09 0.817852\n",
      "1e-08 0.817852\n",
      "1e-07 0.817884\n",
      "1e-06 0.818028\n",
      "1e-05 0.817648\n",
      "0.0001 0.817832\n",
      "0.001 0.81722\n",
      "0.01 0.813432\n",
      "0.1 0.795224\n",
      "Estimated leaderboard score:  0.818028\n",
      "1e-06\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import test_RR\n",
    "from implementations import ridge_regression\n",
    "\n",
    "lambdas = np.logspace(-15, -1, num=15)\n",
    "best_loss = 1000000 # TODO change\n",
    "best_score = 0\n",
    "for lambda_ in lambdas:\n",
    "    loss, score = test_RR(y_train, tx_train, lambda_)\n",
    "    #if loss < best_loss:\n",
    "    #    best_loss = loss\n",
    "    #    best_lambda = lambda_\n",
    "    #    best_score = score\n",
    "    print(lambda_, score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_lambda = lambda_\n",
    "        best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "print(best_lambda)\n",
    "w[\"rr\"], _ = ridge_regression(y_train, tx_train, best_lambda)\n",
    "s[\"rr\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_LR\n",
    "from implementations import logistic_regression\n",
    "\n",
    "gammas = np.logspace(-5, 3, num=15)\n",
    "best_loss = 1000000 # TODO change\n",
    "best_score = 0\n",
    "for gamma in gammas:\n",
    "    loss, score = test_LR(y_train, tx_train, gamma)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_gamma = gamma\n",
    "        best_score = score\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_gamma = gamma\n",
    "        best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "print('best_gamma: ',best_gamma)\n",
    "w[\"lr\"], _ = logistic_regression(y_train, tx_train, np.zeros(tx_train.shape[1]), 1000, best_gamma)\n",
    "s[\"lr\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from cross_validation import test_RLR\n",
    "from implementations import reg_logistic_regression\n",
    "\n",
    "gammas = np.logspace(-20, -9, 10) #100\n",
    "lambdas = np.logspace(-5, 5, 100)\n",
    "best_loss = 10000 # TODO change\n",
    "best_score = 0\n",
    "ii = 0\n",
    "for gamma in gammas:\n",
    "    print('\\n',ii,'\\n')\n",
    "    ii+=1\n",
    "    print('gamma: ',gamma)\n",
    "    for lambda_ in lambdas:\n",
    "        loss, score = test_RLR(y_train, tx_train, lambda_, gamma)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_gamma = gamma\n",
    "            best_lambda = lambda_\n",
    "            best_score = score\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_gamma = gamma\n",
    "            best_lambda = lambda_\n",
    "            best_loss = loss\n",
    "    \n",
    "print(\"Estimated leaderboard score: \", best_score)\n",
    "print('best lambda: ',best_lambda)\n",
    "print('best gamma: ',best_gamma)\n",
    "w[\"rlr\"], _ = reg_logistic_regression(y_train, tx_train, best_lambda, np.zeros(tx_train.shape[1]), 50, best_gamma)\n",
    "s[\"rlr\"] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rr\n",
      "0.818028\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "for method, score in s.items():\n",
    "    if score > best:\n",
    "        best = score\n",
    "        best_method = method\n",
    "\n",
    "print(best_method)\n",
    "print(s[best_method])\n",
    "weights = w[best_method]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from data_preparation import standardize_outliers\n",
    "from feature_selection import build_poly_by_feature\n",
    "\n",
    "DATA_TEST_PATH = \"../Data/test.csv\"\n",
    "_, tx_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tx_test, _, _ = standardize_outliers(tx_test, -999)\n",
    "tx_test = build_poly_by_feature(tx_test, best_degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if best_method in [ \"lr\", \"rlr\" ]:\n",
    "    y_pred = predict_logistic_labels(weights, tx_test, threshold = 0.5)\n",
    "else:\n",
    "    y_pred = predict_labels(weights, tx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = \"../Data/results.csv\"\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
