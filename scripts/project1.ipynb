{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCML Project-1 ~ Team #60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from costs import compute_loss\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (250000,)\n",
      "original tX shape:  (250000, 30)\n",
      "ids shape:  (250000,)\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "from helpers import *\n",
    "\n",
    "DATA_TRAIN_PATH = \"../Data/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "#print the shape of the offset x matrix.\n",
    "print('y shape: ',y.shape)\n",
    "print('original tX shape: ',tX.shape)\n",
    "print('ids shape: ',ids.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Outliers - Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature:  0  ->  38114.0\n",
      "feature:  1  ->  0.0\n",
      "feature:  2  ->  0.0\n",
      "feature:  3  ->  0.0\n",
      "feature:  4  ->  177457.0\n",
      "feature:  5  ->  177457.0\n",
      "feature:  6  ->  177457.0\n",
      "feature:  7  ->  0.0\n",
      "feature:  8  ->  0.0\n",
      "feature:  9  ->  0.0\n",
      "feature:  10  ->  0.0\n",
      "feature:  11  ->  0.0\n",
      "feature:  12  ->  177457.0\n",
      "feature:  13  ->  0.0\n",
      "feature:  14  ->  0.0\n",
      "feature:  15  ->  0.0\n",
      "feature:  16  ->  0.0\n",
      "feature:  17  ->  0.0\n",
      "feature:  18  ->  0.0\n",
      "feature:  19  ->  0.0\n",
      "feature:  20  ->  0.0\n",
      "feature:  21  ->  0.0\n",
      "feature:  22  ->  0.0\n",
      "feature:  23  ->  99913.0\n",
      "feature:  24  ->  99913.0\n",
      "feature:  25  ->  99913.0\n",
      "feature:  26  ->  177457.0\n",
      "feature:  27  ->  177457.0\n",
      "feature:  28  ->  177457.0\n",
      "feature:  29  ->  0.0\n"
     ]
    }
   ],
   "source": [
    "outliers = count_outliers(tX,-999)\n",
    "for feature in range(tX.shape[1]):\n",
    "    print('feature: ',feature,' -> ',outliers[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250000 30\n",
      "(250000, 31)\n",
      "standardized tX shape:  (250000, 31)\n",
      "tX mean shape:  (30,)\n",
      "tX std shape:  (30,)\n"
     ]
    }
   ],
   "source": [
    "#standardization\n",
    "# tX, mean_x, std_x = standardize(tX, mean_x=None, std_x=None)\n",
    "tX, mean_x, std_x = standardize_outliers(tX)\n",
    "print('standardized tX shape: ',tX.shape)\n",
    "print('tX mean shape: ',mean_x.shape)\n",
    "print('tX std shape: ',std_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Histogram of output y\n",
    "plt.hist(y, bins=10, align='mid')\n",
    "plt.title(\"Histogram of output y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of y as a function of all its features (one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyse y as a function of all the other features (one by one)\n",
    "plot_features_by_y(y,tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of polynomial bases, feature by feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.        0.77148 ]\n",
      " [ 5.        0.745616]\n",
      " [ 5.        0.767272]\n",
      " [ 5.        0.74788 ]\n",
      " [ 5.        0.747712]\n",
      " [ 5.        0.746608]\n",
      " [ 4.        0.745392]\n",
      " [ 4.        0.75208 ]\n",
      " [ 5.        0.744768]\n",
      " [ 4.        0.752344]\n",
      " [ 5.        0.749832]\n",
      " [ 0.        0.747256]\n",
      " [ 3.        0.746256]\n",
      " [ 5.        0.76056 ]\n",
      " [ 2.        0.746792]\n",
      " [ 1.        0.744032]\n",
      " [ 5.        0.744688]\n",
      " [ 4.        0.748096]\n",
      " [ 1.        0.744032]\n",
      " [ 0.        0.744448]\n",
      " [ 1.        0.744032]\n",
      " [ 5.        0.75064 ]\n",
      " [ 3.        0.746496]\n",
      " [ 5.        0.749736]\n",
      " [ 5.        0.74916 ]\n",
      " [ 1.        0.744032]\n",
      " [ 4.        0.744088]\n",
      " [ 4.        0.744672]\n",
      " [ 1.        0.744032]\n",
      " [ 5.        0.748272]]\n"
     ]
    }
   ],
   "source": [
    "from poly import *\n",
    "\n",
    "deg = find_best_poly(y, tX[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 108)\n"
     ]
    }
   ],
   "source": [
    "tX = build_optimal(y, tX[:,1:], deg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gradient_descent import least_squares_GD\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX.shape[1])\n",
    "\n",
    "# Start gradient descent.\n",
    "# start_time = datetime.datetime.now()\n",
    "gradient_losses, gradient_ws = least_squares_GD(y, tX, w_initial, gamma, max_iters)\n",
    "# end_time = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from stochastic_gradient_descent import least_squares_SGD\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 1000\n",
    "gamma = 0.01\n",
    "batch_size = 50\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.zeros(tX.shape[1])\n",
    "\n",
    "# Start SGD.\n",
    "stoch_gradient_losses, stoch_gradient_ws = least_squares_SGD(y, tX, w_initial, batch_size, gamma, max_iters)\n",
    "\n",
    "min_stoch_i, min_stoch_loss = get_min_param_index(stoch_gradient_losses)\n",
    "print('min index: ',min_stoch_i)\n",
    "print('min loss: ',min_stoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least squares regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 0.298128567409\n",
      "parameters w:  [ -8.15463208e-02   2.04285166e-01  -1.67302425e-01   3.18274634e-02\n",
      "  -2.31425497e-03   5.66347799e-05  -3.06976022e-01  -1.48080723e-04\n",
      "   2.99693062e-02  -3.97742027e-03   1.35071715e-04  -3.29302852e-01\n",
      "  -6.80365662e-03   7.00099210e-03  -4.76415319e-04   8.64787061e-06\n",
      "   1.11058731e-01   3.68764996e-02  -2.00713886e-02   3.29681115e-03\n",
      "  -1.69193493e-04   1.21789423e-01   8.98562899e-02  -1.02455630e-01\n",
      "  -5.58703282e-03   1.33832811e-02  -2.96723892e-01   2.97044036e-01\n",
      "  -1.02189068e-01   1.33182739e-02  -5.75359177e-04  -2.25928885e-01\n",
      "  -2.79231309e-02   1.73078000e-02  -1.74703585e-03   2.39099441e-01\n",
      "  -4.28414817e-02   6.45656941e-03   4.86030059e-03  -2.40959854e-02\n",
      "   1.49954720e-02  -1.22053412e-03   2.16914847e-05   4.04791245e-07\n",
      "  -2.00108455e+02   3.53012615e-02  -6.35561759e-03   3.15073539e-04\n",
      "  -9.44120830e-02   6.31003385e-02  -1.24695206e-02   8.62080913e-04\n",
      "  -1.86604113e-05   1.80497469e-01   6.62258858e-02  -4.73119288e-02\n",
      "   3.90911868e+01  -1.14804711e-01   1.46539025e-02  -7.29718530e-04\n",
      "   1.20194873e-05  -4.90032095e-04  -3.24045594e-02  -2.66286689e-04\n",
      "   3.83436198e+01  -5.95575002e-02   9.04970467e-03  -4.74882373e-04\n",
      "   5.95126709e-06   3.66996311e-03  -6.31875920e-02  -1.31531460e-03\n",
      "   2.87830943e-03   1.24623306e-03   2.23984728e-04  -2.36688037e-02\n",
      "  -7.37108430e-02   2.29519258e-02  -2.48292271e-03   8.01370295e-05\n",
      "  -1.84414277e-01  -1.38859295e-01   6.29499729e-02   1.68547416e-01\n",
      "  -8.86333894e-02   2.52592970e-02  -3.01909116e-03   1.25008899e-04\n",
      "  -7.52101405e-03   1.78646829e-01   2.72428802e-03  -1.27977828e-02\n",
      "   9.33079174e-05   6.80587791e-05   1.88756477e-01  -3.87180475e-02\n",
      "   3.04545728e-03  -8.27733427e-05  -2.64495268e-03   2.24485798e-01\n",
      "   1.34098971e-03  -2.02315527e-02  -1.22448727e-03   1.69466260e+02\n",
      "  -6.86082739e-02   1.56196707e-02  -1.21004519e-03   3.32353650e-05]\n"
     ]
    }
   ],
   "source": [
    "from least_squares import least_squares\n",
    "\n",
    "# start_ls_time = datetime.datetime.now()\n",
    "ls_wopt, ls_loss = least_squares(y,tX)\n",
    "# end_ls_time = datetime.datetime.now()\n",
    "print('loss=',ls_loss)\n",
    "print('parameters w: ',ls_wopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression using normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ridge_regression import ridge_regression\n",
    "\n",
    "w_ridge = ridge_regression(y, tX, 0.01)\n",
    "err = compute_loss(y, tX, w_ridge)\n",
    "\n",
    "print('loss: ',err)\n",
    "print('parameters w: ',w_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ridge_regression import cross_validation_ridge_regression\n",
    "\n",
    "cross_validation_ridge_regression(y,tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using gradient descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=0, the loss=0.693147180559945\n",
      "Current iteration=1000, the loss=0.4535788439094665\n",
      "Current iteration=2000, the loss=0.2554613354813791\n",
      "Current iteration=3000, the loss=0.08502833099738107\n"
     ]
    }
   ],
   "source": [
    "from helpers import de_standardize\n",
    "from logistic_regression import logistic_regression_gradient_descent\n",
    "from plots import visualization\n",
    "\n",
    "lr_loss, lr_w = logistic_regression_gradient_descent(y, tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized logistic regression using gradient descent or SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_GD(y, tX, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_SGD(y, tX, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_LS(y, tX, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_RR(y, tX, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_LR(y, tX, ratio=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_RLR(y, tX, ratio=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gradient Descent\n",
    "weights = gradient_ws[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "weights = stoch_gradient_ws[min_stoch_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Least Squares\n",
    "weights = ls_wopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "weights = w_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "weights = lr_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# subtract features\n",
    "weights = np.ones(31)\n",
    "# weights[[0,4,5,6,23,24,25,26,27,28]] = 0\n",
    "weights[[0,12,13,15,16,18,19,20,21,23,25,26,28,29]] = 0\n",
    "print(weights)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../Data/test.csv\" # TODO: download test data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568238 30\n",
      "(568238, 31)\n"
     ]
    }
   ],
   "source": [
    "tX_test, _, _ = standardize_outliers(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from logistic_regression import sigmoid\n",
    "def predict_logistic_labels(weights, data):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\n",
    "    \n",
    "    y_pred = sigmoid(np.dot(data, weights))\n",
    "#     y_pred[np.where(y_pred <= 0)] = -1\n",
    "#     y_pred[np.where(y_pred > 0)] = 1\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = predict_logistic_labels(weights,tX_test)\n",
    "p[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final score: \t\t 1.0\n"
     ]
    }
   ],
   "source": [
    "# logistic\n",
    "OUTPUT_PATH = '../Data/results.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_logistic_labels(weights, tX_test)\n",
    "y_pred = y_pred.reshape(1,y_pred.shape[0]).flatten()\n",
    "print('final score: \\t\\t',(y_pred == y_test).sum()/y_pred.size)\n",
    "# create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. ...,  1.  1. -1.]\n",
      "final score: \t\t 0.276665763289\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../Data/results.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "print('final score: \\t\\t',(y_pred == y_test).sum()/y_pred.size)\n",
    "# create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: \t\t\t 568238\n",
      "correct predictions: \t 568238\n",
      "wrong predictions: \t 0\n",
      "final score: \t\t 1.0\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "for row in range(0,len(y_pred)):\n",
    "    if y_pred[row] == y_test[row]:\n",
    "        count_true += 1\n",
    "#         print(row,' True')\n",
    "\n",
    "total_pred = y_test.shape[0]\n",
    "print('total: \\t\\t\\t',total_pred)\n",
    "print('correct predictions: \\t', count_true)\n",
    "print('wrong predictions: \\t', total_pred-count_true)\n",
    "print('final score: \\t\\t', count_true/y_pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
